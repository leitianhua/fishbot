#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
èµ„æºæœç´¢æ ¸å¿ƒæ¨¡å—
"""

import os
import re
import time
import threading
import tomllib
import json
from concurrent.futures import ThreadPoolExecutor
from typing import List, Dict, Any, Optional, Tuple
from loguru import logger

# å¯¼å…¥å·¥å…·ç±»ï¼ˆä½¿ç”¨ç»å¯¹å¯¼å…¥ï¼‰
from utils.search import ResourceSearch
from utils.quark import Quark
from utils.baidu import Baidu
from utils.database import get_db_instance

class ResourceCore:
    """èµ„æºæœç´¢æ ¸å¿ƒç±»"""
    
    def __init__(self, plugin_dir=None):
        """åˆå§‹åŒ–æ ¸å¿ƒç±»
        
        Args:
            plugin_dir: æ’ä»¶ç›®å½•è·¯å¾„ï¼Œé»˜è®¤ä¸ºNoneï¼ˆè‡ªåŠ¨è·å–ï¼‰
        """
        # è·å–å½“å‰æ¨¡å—æ‰€åœ¨ç›®å½•
        self.utils_dir = os.path.dirname(os.path.abspath(__file__))
        
        # è·å–æ’ä»¶ç›®å½•
        if plugin_dir is None:
            self.plugin_dir = os.path.dirname(self.utils_dir)
        else:
            self.plugin_dir = plugin_dir
            
        # åˆå§‹åŒ–é…ç½®
        self.conf = None
        
        # åˆå§‹åŒ–æ•°æ®åº“ç®¡ç†å™¨
        self.db = get_db_instance()
        
        # åŠ è½½é…ç½®
        self._load_config()
        
        # å¦‚æœé…ç½®åŠ è½½æˆåŠŸï¼Œåˆå§‹åŒ–æ¸…ç†çº¿ç¨‹
        if self.conf:
            # ä»é…ç½®ä¸­è·å–è¿‡æœŸæ—¶é—´
            general_conf = self.conf.get("general", {})
            self.expired_time = general_conf.get("expired_time", 30)
            
            # å¼€å¯ä¸€ä¸ªçº¿ç¨‹æ¯åˆ†é’Ÿæ¸…é™¤è¿‡æœŸèµ„æº
            self.clear_expired_resources_thread = threading.Thread(target=self.clear_expired_resources)
            self.clear_expired_resources_thread.daemon = True  # è®¾ç½®ä¸ºå®ˆæŠ¤çº¿ç¨‹
            self.clear_expired_resources_thread.start()
            
            logger.info("èµ„æºæœç´¢æ ¸å¿ƒåˆå§‹åŒ–æˆåŠŸ")
        else:
            logger.error("èµ„æºæœç´¢æ ¸å¿ƒåˆå§‹åŒ–å¤±è´¥ï¼Œé…ç½®æœªåŠ è½½")
    
    def _load_config(self):
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            # è·å–é…ç½®æ–‡ä»¶è·¯å¾„ - æ”¹ä¸ºä»utilsç›®å½•ä¸‹åŠ è½½
            config_path = os.path.join(self.utils_dir, "config.toml")
            logger.debug(f"åŠ è½½é…ç½®æ–‡ä»¶: {config_path}")
            
            # è¯»å–é…ç½®æ–‡ä»¶
            with open(config_path, "rb") as f:
                config = tomllib.load(f)
                
            # éªŒè¯é…ç½®
            if not config:
                logger.error("é…ç½®æ–‡ä»¶ä¸ºç©º")
                return
                
            # è·å–å¹¶éªŒè¯å¤¸å…‹è´¦å·é…ç½®
            quark_accounts = config.get("accounts", {}).get("quark", [])
            if not quark_accounts:
                logger.error("æœªé…ç½®å¤¸å…‹è´¦å·ï¼Œæ’ä»¶æ— æ³•æ­£å¸¸å·¥ä½œ")
                return
                
            # éªŒè¯æ¯ä¸ªå¤¸å…‹è´¦å·
            valid_quark_accounts = []
            for account in quark_accounts:
                cookie = account.get("cookie")
                if not cookie:
                    logger.warning("å¤¸å…‹è´¦å·ç¼ºå°‘cookie")
                    continue
                    
                if self._verify_quark_account(cookie):
                    valid_quark_accounts.append(account)
                else:
                    logger.warning("å¤¸å…‹è´¦å·éªŒè¯å¤±è´¥")
            
            if not valid_quark_accounts:
                logger.error("æ²¡æœ‰æœ‰æ•ˆçš„å¤¸å…‹è´¦å·ï¼Œæ’ä»¶æ— æ³•æ­£å¸¸å·¥ä½œ")
                return
                
            # æ›´æ–°é…ç½®ä¸­çš„æœ‰æ•ˆè´¦å·
            config["accounts"]["quark"] = valid_quark_accounts
            
            # ä¿å­˜é…ç½®
            self.conf = config
            logger.info("èµ„æºæœç´¢é…ç½®åŠ è½½æˆåŠŸ")
            
        except Exception as e:
            logger.error(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
    
    def _verify_quark_account(self, cookie):
        """éªŒè¯å¤¸å…‹ç½‘ç›˜è´¦å·æ˜¯å¦æœ‰æ•ˆ
        
        Args:
            cookie: å¤¸å…‹ç½‘ç›˜cookie
            
        Returns:
            bool: è´¦å·æ˜¯å¦æœ‰æ•ˆ
        """
        try:
            # æ„å»ºè¯·æ±‚å¤´
            headers = {
                'authority': 'pan.quark.cn',
                'accept': 'application/json, text/plain, */*',
                'sec-ch-ua': '"Not.A/Brand";v="8", "Chromium";v="114", "Microsoft Edge";v="114"',
                'sec-ch-ua-mobile': '?0',
                'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36 Edg/114.0.1823.67',
                'sec-ch-ua-platform': '"Windows"',
                'sec-fetch-site': 'same-site',
                'sec-fetch-mode': 'cors',
                'sec-fetch-dest': 'empty',
                'referer': 'https://pan.quark.cn/',
                'accept-encoding': 'gzip, deflate, br',
                'accept-language': 'zh-CN,zh;q=0.9',
                'cookie': cookie
            }
            
            # è°ƒç”¨è·å–è´¦æˆ·ä¿¡æ¯çš„API
            import requests
            url = "https://pan.quark.cn/account/info"
            params = {"fr": "pc", "platform": "pc"}
            
            response = requests.get(url, headers=headers, params=params, timeout=10)
            account_info = response.json()
            
            # æ£€æŸ¥å“åº”ä¸­æ˜¯å¦åŒ…å«è´¦æˆ·ä¿¡æ¯
            if account_info and account_info.get("data"):
                nickname = account_info["data"].get("nickname", "")
                logger.info(f"å¤¸å…‹ç½‘ç›˜è´¦å·: {nickname}")
                return True
            else:
                logger.error(f"å¤¸å…‹ç½‘ç›˜è´¦å·éªŒè¯å¤±è´¥: {account_info.get('message', 'æœªçŸ¥é”™è¯¯')}")
                return False
        except Exception as e:
            logger.error(f"éªŒè¯å¤¸å…‹è´¦å·æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            return False
    
    # æ¯åˆ†é’Ÿæ¸…é™¤è¿‡æœŸèµ„æº
    def clear_expired_resources(self):
        """æ¸…é™¤è¿‡æœŸèµ„æºçš„çº¿ç¨‹å‡½æ•°"""
        while True:
            try:
                quark = Quark(self.conf)
                quark.del_expired_resources(self.expired_time)
                time.sleep(60)  # æ¯åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡
            except Exception as e:
                logger.error(f"æ¸…é™¤è¿‡æœŸèµ„æºå¤±è´¥: {e}")
                time.sleep(60)
    
    def search_and_store(self, keyword: str, limit: int = 5) -> List[Dict[str, Any]]:
        """æœç´¢èµ„æºå¹¶è½¬å­˜åˆ°ç½‘ç›˜
        
        Args:
            keyword: æœç´¢å…³é”®è¯
            limit: æœ€å¤§ç»“æœæ•°é‡ï¼Œé»˜è®¤ä¸º5
            
        Returns:
            åŒ…å«è½¬å­˜åèµ„æºä¿¡æ¯çš„åˆ—è¡¨ï¼Œæ¯é¡¹åŒ…å«:
            - title: èµ„æºæ ‡é¢˜
            - url: èµ„æºé“¾æ¥
            - is_time: æ˜¯å¦ä¸ºä¸´æ—¶èµ„æº(1ä¸ºæ˜¯)
        """
        if not self.conf:
            logger.error("é…ç½®æœªåŠ è½½ï¼Œæ— æ³•æ‰§è¡Œæœç´¢")
            return []
            
        # è·å–é…ç½®
        general_conf = self.conf.get("general", {})
        search_timeout = general_conf.get("search_timeout", 10)  # é»˜è®¤10ç§’è¶…æ—¶
        max_threads = general_conf.get("max_search_threads", 0)  # é»˜è®¤ä¸é™åˆ¶çº¿ç¨‹æ•°
        
        logger.info(f'æœç´¢å…³é”®å­—: {keyword}ï¼Œæœ€å¤§ç»“æœæ•°: {limit}ï¼Œè¶…æ—¶: {search_timeout}ç§’')
        start_time = time.time()
        
        # åˆ›å»ºèµ„æºæœç´¢å¯¹è±¡
        rs = ResourceSearch()
        
        # è‡ªåŠ¨è·å–æ‰€æœ‰æœç´¢æ–¹æ³•ï¼ˆä»¥search_sourceå¼€å¤´çš„æ–¹æ³•ï¼‰
        all_search_methods = []
        for method_name in dir(rs):
            if method_name.startswith('search_source') and callable(getattr(rs, method_name)):
                all_search_methods.append(method_name)
        
        # æ ¹æ®é…ç½®å¯ç”¨æˆ–ç¦ç”¨æœç´¢æº
        sources_config = self.conf.get("sources", {})
        enabled_methods = []
        
        for method in all_search_methods:
            # æå–æºç¼–å·ï¼ˆä¾‹å¦‚ä»search_source1ä¸­æå–1ï¼‰
            source_num = method.replace("search_source", "")
            # æ£€æŸ¥é…ç½®æ˜¯å¦å¯ç”¨è¯¥æº
            if sources_config.get(f"source{source_num}", True):
                enabled_methods.append(method)
            else:
                logger.info(f"æœç´¢æº{source_num}å·²ç¦ç”¨: {method}")
        
        logger.info(f"æ£€æµ‹åˆ°{len(all_search_methods)}ä¸ªæœç´¢æºï¼Œå¯ç”¨{len(enabled_methods)}ä¸ª: {', '.join(enabled_methods)}")
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œæœç´¢ï¼Œæ”¯æŒæœ€å¤§çº¿ç¨‹æ•°æ§åˆ¶
        thread_count = max_threads if max_threads > 0 else None
        with ThreadPoolExecutor(max_workers=thread_count) as executor:
            # åˆ›å»ºå¸¦è¶…æ—¶çš„ä»»åŠ¡
            future_to_method = {
                executor.submit(self._search_with_timeout, rs, method, keyword, search_timeout): method
                for method in enabled_methods
            }
            
            # æ”¶é›†ç»“æœ
            all_results = []
            for future in ThreadPoolExecutor().map(lambda f: (f, f.result()), future_to_method):
                future_obj, results = future
                method = future_to_method[future_obj]
                if isinstance(results, Exception):
                    logger.error(f"æœç´¢æº {method} å‘ç”Ÿé”™è¯¯: {results}")
                    continue
                if results:
                    logger.info(f"æœç´¢æº {method} è¿”å› {len(results)} æ¡ç»“æœ")
                    all_results.extend(results)
                else:
                    logger.debug(f"æœç´¢æº {method} æœªè¿”å›ç»“æœ")
        
        # åˆ›å»ºè½¬å­˜å·¥å…·
        quark = Quark(self.conf)
        baidu = Baidu(self.conf)
        
        # å­˜å‚¨ç»“æœ
        unique_results = []
        count = 0
        
        # å¤„ç†æœç´¢ç»“æœ
        for item in all_results:
            # é™åˆ¶ç»“æœæ•°é‡
            if count >= limit:
                logger.debug(f"ç»“æœå·²è¾¾åˆ°{limit}æ¡ä¸Šé™ï¼Œåœæ­¢å¤„ç†")
                break
                
            url = item.get('url')
            if not url:
                logger.debug(f"è·³è¿‡æ²¡æœ‰URLçš„é¡¹: {item}")
                continue
            
            logger.debug(f"å¤„ç†æœç´¢ç»“æœ: {item.get('title', 'æœªçŸ¥')} - {url}")
                
            try:
                file_not_exist = False
                file_name = ''
                share_link = ''
                
                # æ ¹æ®é“¾æ¥ç±»å‹é€‰æ‹©ç›¸åº”çš„ç½‘ç›˜å¤„ç†
                if 'quark' in url:
                    logger.info(f"è½¬å­˜å¤¸å…‹é“¾æ¥: {url}")
                    file_not_exist, file_name, share_link = quark.store(url)
                elif 'baidu' in url:
                    logger.info(f"è½¬å­˜ç™¾åº¦é“¾æ¥: {url}")
                    # å¦‚æœéœ€è¦æ”¯æŒç™¾åº¦ç½‘ç›˜
                    # file_not_exist, file_name, share_link = baidu.store(url)
                    continue
                else:
                    logger.warning(f"æœªçŸ¥é“¾æ¥ç±»å‹ï¼Œè·³è¿‡: {url}")
                    continue
                    
                # å¦‚æœæˆåŠŸå¤„ç†ï¼Œæ·»åŠ åˆ°ç»“æœ
                if file_name and share_link:
                    logger.info(f'{"æ–°è½¬å­˜" if file_not_exist else "å·²å­˜åœ¨"}: {file_name} - {share_link}')
                    item['title'] = file_name
                    item['url'] = share_link
                    item['is_time'] = 1
                    unique_results.append(item)
                    count += 1
                else:
                    logger.warning(f"é“¾æ¥å¤„ç†ç»“æœä¸å®Œæ•´: file_name={file_name}, share_link={share_link}")
                    
            except Exception as e:
                logger.error(f'è½¬å­˜å¤±è´¥ "{item.get("title", "æœªçŸ¥")}" {url}: {e}')
                continue
        
        # è®°å½•æœç´¢å†å²
        self.db.record_search(keyword, len(unique_results))
        
        # è®°å½•æ‰§è¡Œæ—¶é—´
        execution_time = time.time() - start_time
        logger.info(f"æœç´¢æ‰§è¡Œè€—æ—¶: {execution_time:.2f} ç§’, æ‰¾åˆ°ç»“æœ: {len(unique_results)}")
        
        return unique_results
    
    def _search_with_timeout(self, search_obj, method_name, keyword, timeout):
        """å¸¦è¶…æ—¶æ§åˆ¶çš„æœç´¢æ–¹æ³•
        
        Args:
            search_obj: æœç´¢å¯¹è±¡
            method_name: æ–¹æ³•å
            keyword: æœç´¢å…³é”®è¯
            timeout: è¶…æ—¶ç§’æ•°
            
        Returns:
            æœç´¢ç»“æœæˆ–å¼‚å¸¸
        """
        import concurrent.futures
        
        method = getattr(search_obj, method_name)
        with ThreadPoolExecutor(max_workers=1) as executor:
            future = executor.submit(method, keyword)
            try:
                return future.result(timeout=timeout)
            except concurrent.futures.TimeoutError:
                logger.warning(f"æœç´¢æº {method_name} è¶…æ—¶ ({timeout}ç§’)")
                return []
            except Exception as e:
                logger.error(f"æœç´¢æº {method_name} å‘ç”Ÿé”™è¯¯: {e}")
                return e
    
    @staticmethod
    def format_results(results: List[Dict[str, Any]], keyword: str) -> str:
        """æ ¼å¼åŒ–æœç´¢ç»“æœä¸ºå¯è¯»æ–‡æœ¬
        
        Args:
            results: æœç´¢ç»“æœåˆ—è¡¨
            keyword: åŸå§‹æœç´¢å…³é”®è¯
            
        Returns:
            æ ¼å¼åŒ–åçš„æ–‡æœ¬
        """
        if not results:
            return f"æœç´¢å†…å®¹ï¼š{keyword}\nâš æœªæ‰¾åˆ°ï¼Œå¯æ¢ä¸ªå…³é”®è¯å°è¯•å“¦\nâ€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\nâš æœç´¢æŒ‡ä»¤ï¼šæœ:XXX æˆ– æœç´¢:XXX"
            
        reply = f"æœç´¢å†…å®¹ï¼š{keyword}\nâ€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”"
        for item in results:
            reply += f"\nğŸŒï¸{item.get('title', 'æœªçŸ¥æ ‡é¢˜')}"
            reply += f"\n{item.get('url', 'æœªçŸ¥URL')}"
            reply += "\nâ€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”"
            
        if any(item.get('is_time', 0) == 1 for item in results):
            reply += "\nâš èµ„æºæ¥æºç½‘ç»œï¼Œ30åˆ†é’Ÿååˆ é™¤"
            reply += "\nâš é¿å…å¤±æ•ˆï¼Œè¯·åŠæ—¶ä¿å­˜~ğŸ’¾"
            
        return reply
    
    def get_search_history(self, limit: int = 10) -> List[Dict[str, Any]]:
        """è·å–æœç´¢å†å²è®°å½•
        
        Args:
            limit: è¿”å›çš„å†å²è®°å½•æ•°é‡é™åˆ¶
            
        Returns:
            List[Dict[str, Any]]: æœç´¢å†å²è®°å½•åˆ—è¡¨
        """
        if not self.db:
            logger.error("æ•°æ®åº“æœªåˆå§‹åŒ–ï¼Œæ— æ³•è·å–æœç´¢å†å²")
            return []
            
        try:
            records = self.db.get_search_history(limit)
            results = []
            for record in records:
                results.append({
                    'id': record[0],
                    'keyword': record[1],
                    'result_count': record[2],
                    'search_time': record[3]
                })
            return results
        except Exception as e:
            logger.error(f"è·å–æœç´¢å†å²å¤±è´¥: {e}")
            return [] 